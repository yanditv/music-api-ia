# ğŸš€ ConfiguraciÃ³n para Primera Vez

Esta guÃ­a explica exactamente quÃ© esperar cuando ejecutas la API por primera vez.

## ğŸ“¥ Â¿QuÃ© se descarga automÃ¡ticamente?

La primera vez que hagas una peticiÃ³n a `/generate/`, se descargarÃ¡n estos modelos:

### Modelos de Bark (Total: ~6.6GB)

```
ğŸ“¦ suno/bark_v0/
â”œâ”€â”€ text_2.pt      (~1.2GB) - Modelo de procesamiento de texto
â”œâ”€â”€ coarse_2.pt    (~2.4GB) - Modelo de audio grueso
â””â”€â”€ fine_2.pt      (~3.0GB) - Modelo de audio fino

ğŸ“¦ bert-base-multilingual-cased/
â”œâ”€â”€ pytorch_model.bin  (~650MB) - Modelo BERT
â”œâ”€â”€ tokenizer.json     (~15MB)  - Tokenizador
â”œâ”€â”€ vocab.txt         (~996KB)  - Vocabulario
â””â”€â”€ config.json       (~1KB)   - ConfiguraciÃ³n
```

### UbicaciÃ³n de archivos

```
app/models/
â”œâ”€â”€ transformers/           # Modelos de Hugging Face Transformers
â”‚   â””â”€â”€ models--bert-base-multilingual-cased/
â”œâ”€â”€ cache/suno/bark_v0/     # Modelos principales de Bark
â”‚   â”œâ”€â”€ text_2.pt
â”‚   â”œâ”€â”€ coarse_2.pt
â”‚   â””â”€â”€ fine_2.pt
â”œâ”€â”€ torch/hub/              # Cache de PyTorch
â””â”€â”€ huggingface/            # Cache general de HF
```

## â±ï¸ Tiempos esperados

### Primera ejecuciÃ³n completa:

1. **Iniciar servidor**: 1-2 minutos ğŸŒ
   - ğŸ“¥ Descarga modelos: 30-90 segundos (si es primera vez)
   - ğŸ§  Carga en memoria: 10-15 segundos
   - âš¡ Servidor listo: inmediato
2. **Primera peticiÃ³n**: 2-5 segundos âš¡
   - ğŸµ Genera audio: 2-5 segundos (modelos ya en memoria)

### Ejecuciones posteriores:

1. **Iniciar servidor**: 10-15 segundos ğŸš€
   - ğŸ§  Carga modelos en memoria: 10-15 segundos (ya descargados)
   - âš¡ Servidor listo: inmediato
2. **Todas las peticiones**: 2-5 segundos âš¡âš¡

## ğŸ–¥ï¸ Ejemplo paso a paso

### 1. Instalar dependencias (solo primera vez)

```bash
git clone <your-repo>
cd music-api-ia
python -m venv .venv
source .venv/bin/activate
pip install -r requirements.txt
```

### 2. Iniciar servidor

```bash
python -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000
```

**Salida esperada (primera vez):**

```
ğŸš€ Precargando modelos de Bark al iniciar la API...
â³ Si es la primera vez, esto descargarÃ¡ ~6.6GB de modelos...

Downloading (â€¦)lve/main/config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 570/570 [00:00<00:00, 123kB/s]
Downloading (â€¦)main/pytorch_model.bin: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 625M/625M [01:23<00:00, 7.50MB/s]
Downloading (â€¦)okenizer_config.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 25.0k/25.0k [00:00<00:00, 456kB/s]
Downloading (â€¦)solve/main/vocab.txt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 996k/996k [00:00<00:00, 1.20MB/s]
Downloading (â€¦)/main/tokenizer.json: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 15.6M/15.6M [00:02<00:00, 6.50MB/s]

Downloading text_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1.21G/1.21G [02:15<00:00, 8.95MB/s]
Downloading coarse_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2.42G/2.42G [04:32<00:00, 8.88MB/s]
Downloading fine_2.pt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3.01G/3.01G [05:41<00:00, 8.82MB/s]

âœ… Modelos cargados correctamente y listos para usar!
ğŸ“ Cache de modelos configurado en: /path/to/app/models

INFO:     Will watch for changes in these directories: ['/path/to/music-api-ia']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using StatReload
INFO:     Started server process [12346]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

**Salida esperada (siguientes veces):**

```
ğŸš€ Precargando modelos de Bark al iniciar la API...
â³ Si es la primera vez, esto descargarÃ¡ ~6.6GB de modelos...
âœ… Modelos cargados correctamente y listos para usar!
ğŸ“ Cache de modelos configurado en: /path/to/app/models

INFO:     Will watch for changes in these directories: ['/path/to/music-api-ia']
INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)
INFO:     Started reloader process [12345] using StatReload
INFO:     Started server process [12346]
INFO:     Waiting for application startup.
INFO:     Application startup complete.
```

### 3. Primera peticiÃ³n (RÃPIDA - los modelos ya estÃ¡n cargados!)

```bash
curl -X POST http://localhost:8000/generate/ \
  -H "Content-Type: application/json" \
  -d '{"text": "Hello world, this is my first test", "voice": "v2/en_speaker_6"}' \
  --output first_audio.wav
```

**Salida en terminal del servidor:**

```
ğŸµ Generando audio para: 'Hello world, this is my first test' con voz: v2/en_speaker_6
Audio guardado en: generated_audio/abc123-def456.wav
```

### 4. Segunda peticiÃ³n (TambiÃ©n RÃPIDA!)

```bash
curl -X POST http://localhost:8000/generate/ \
  -H "Content-Type: application/json" \
  -d '{"text": "This second request will be much faster!", "voice": "v2/en_speaker_3"}' \
  --output second_audio.wav
```

**Salida en terminal:**

```
ğŸµ Generando audio para: 'This second request will be much faster!' con voz: v2/en_speaker_3
Audio guardado en: generated_audio/xyz789-abc123.wav
```

## ğŸ’¾ Uso de espacio en disco

DespuÃ©s de la primera ejecuciÃ³n:

```
du -sh app/models/
6.6G    app/models/
```

**Desglose:**

- `cache/suno/bark_v0/`: ~6.6GB (modelos principales)
- `transformers/`: ~650MB (BERT)
- `torch/`: ~50MB (cache)
- `huggingface/`: ~20MB (metadatos)

## ğŸ§¹ Limpiar cache (opcional)

Si quieres empezar de cero:

```bash
rm -rf app/models/
```

En la siguiente peticiÃ³n, se volverÃ¡n a descargar todos los modelos.

## âœ… Verificar que todo funciona

### Test rÃ¡pido despuÃ©s de la primera descarga:

```bash
# 1. Reiniciar servidor
# 2. Hacer peticiÃ³n de prueba
curl -X POST http://localhost:8000/generate/ \
  -H "Content-Type: application/json" \
  -d '{"text": "Testing after restart", "voice": "v2/en_speaker_0"}' \
  --output test.wav

# DeberÃ­a tomar solo 10-15 segundos (no hay descarga)
```

### Test de voces en espaÃ±ol:

```bash
curl -X POST http://localhost:8000/generate/ \
  -H "Content-Type: application/json" \
  -d '{"text": "Hola, esta es una prueba en espaÃ±ol", "voice": "v2/es_speaker_2"}' \
  --output spanish_test.wav
```

## ğŸ†˜ Si algo sale mal

### Error comÃºn: "No space left on device"

- **Causa**: No hay espacio para 6.6GB
- **SoluciÃ³n**: Liberar espacio en disco

### Error: "Connection timeout"

- **Causa**: Descarga lenta de modelos
- **SoluciÃ³n**: Esperar mÃ¡s tiempo o mejorar conexiÃ³n

### Error: "CUDA out of memory"

- **Causa**: GPU con poca memoria
- **SoluciÃ³n**: Se usarÃ¡ CPU automÃ¡ticamente (mÃ¡s lento pero funciona)

---

**ğŸ‰ Â¡Una vez completada la primera descarga, la API serÃ¡ muy rÃ¡pida!**
